{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwS1zS1ltcjyDQc9Oa4fan",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varmagsr/DeepFace/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "v56x-LajT-LL"
      },
      "outputs": [],
      "source": [
        "#!pip install deepface\n",
        "from deepface import DeepFace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1_path = \"/content/p1.jpg\"\n",
        "img2_path = \"/content/p7.jpg\"\n"
      ],
      "metadata": {
        "id": "HL22jGVzVDVm"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Facenet'"
      ],
      "metadata": {
        "id": "RfTuNxxadorj"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify Method will will take 2 images to compare if both the faces are same, and Model_name with which we want to process the match(VGG-Face, Facenet(Google), OpenFace, Facebook DeepFace, DeepID, Dlib, ArcFace)\n",
        "DeepFace.verify(img1_path= img1_path, img2_path= img2_path, model_name= model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iVqEw6AU5F0",
        "outputId": "0b8180df-9bc2-41f7-e544-cfc66676d3fe"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'verified': False,\n",
              " 'distance': 0.6245705900196268,\n",
              " 'threshold': 0.4,\n",
              " 'model': 'Facenet',\n",
              " 'detector_backend': 'opencv',\n",
              " 'similarity_metric': 'cosine',\n",
              " 'facial_areas': {'img1': {'x': 168, 'y': 389, 'w': 407, 'h': 407},\n",
              "  'img2': {'x': 35, 'y': 24, 'w': 101, 'h': 101}},\n",
              " 'time': 1.48}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It Takes 1 source image and finds the matching images form the given path/folder which contains diffrenr face images.\n",
        "DeepFace.find(img1_path, db_path= \"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-9gwQfDsyor",
        "outputId": "2edb20a4-1644-4f15-fa48-05b71e0d499f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-02-20 04:31:01 - There are 7 representations found in representations_vgg_face.pkl\n",
            "24-02-20 04:31:03 - find function lasts 1.9854326248168945 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[          identity  target_x  target_y  target_w  target_h  source_x  \\\n",
              " 0  /content/p1.jpg       168       389       407       407       168   \n",
              " 1  /content/p5.jpg       487       167       271       271       168   \n",
              " 2  /content/p4.jpg       228        95       235       235       168   \n",
              " 3  /content/p2.jpg       314       303       208       208       168   \n",
              " \n",
              "    source_y  source_w  source_h  threshold  distance  \n",
              " 0       389       407       407       0.68  0.000000  \n",
              " 1       389       407       407       0.68  0.586581  \n",
              " 2       389       407       407       0.68  0.604281  \n",
              " 3       389       407       407       0.68  0.678242  ]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It takes 1 image and verifys the diffrent parameters from the face. like...Age, Gender, Emotion & race...\n",
        "DeepFace.analyze(img_path = img1_path, actions = [\"age\", \"gender\", \"emotion\", \"race\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHBXGouZvnc1",
        "outputId": "8299db0b-681f-40a2-8109-0512b49c8e68"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: race: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'age': 36,\n",
              "  'region': {'x': 168, 'y': 389, 'w': 407, 'h': 407},\n",
              "  'face_confidence': 6.0952069702907465,\n",
              "  'gender': {'Woman': 0.006429783388739452, 'Man': 99.99357461929321},\n",
              "  'dominant_gender': 'Man',\n",
              "  'emotion': {'angry': 0.41184225119650364,\n",
              "   'disgust': 0.000528223881701706,\n",
              "   'fear': 5.494856089353561,\n",
              "   'happy': 33.35830569267273,\n",
              "   'sad': 1.492939330637455,\n",
              "   'surprise': 0.0007393196938210167,\n",
              "   'neutral': 59.24078822135925},\n",
              "  'dominant_emotion': 'neutral',\n",
              "  'race': {'asian': 0.030736037297174335,\n",
              "   'indian': 3.199269622564316,\n",
              "   'black': 0.05964274168945849,\n",
              "   'white': 57.603758573532104,\n",
              "   'middle eastern': 33.60052406787872,\n",
              "   'latino hispanic': 5.50607442855835},\n",
              "  'dominant_race': 'white'}]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ]
}